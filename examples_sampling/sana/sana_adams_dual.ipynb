{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scpark/miniconda3/envs/sana/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/scpark/miniconda3/envs/sana/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/scpark/miniconda3/envs/sana/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.99it/s]\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:01<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<backbones.sana.SANA object at 0x76b329350550>\n"
     ]
    }
   ],
   "source": [
    "from backbones.sana import SANA\n",
    "\n",
    "# 사용 예\n",
    "model = SANA()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_compare(imgs):\n",
    "    fig, axes = plt.subplots(1, len(imgs), figsize=(18, 10))\n",
    "    for i in range(len(imgs)):\n",
    "        axes[i].imshow(imgs[i]); axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:06, 14.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.34it/s]\n",
      " 80%|████████  | 16/20 [00:02<00:00,  6.54it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m dpm_sample \u001b[38;5;241m=\u001b[39m pixel_samples[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m solver \u001b[38;5;241m=\u001b[39m Adams_Dual_Solver(model_fn, noise_schedule, algorithm_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdual_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m latent_samples \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_uniform_flow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pixel_samples \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode_vae(latent_samples)\n\u001b[1;32m     23\u001b[0m adams1_sample \u001b[38;5;241m=\u001b[39m pixel_samples[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/logpx_samplers_scpark/solvers/adams_dual_solver.py:102\u001b[0m, in \u001b[0;36mAdams_Dual_Solver.sample\u001b[0;34m(self, x, steps, skip_type, order, flow_shift, use_corrector, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m hist[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fn(x_pred, timesteps[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_corrector:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# ===corrector===\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     x_corr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m x_corr\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/logpx_samplers_scpark/solvers/adams_dual_solver.py:55\u001b[0m, in \u001b[0;36mAdams_Dual_Solver.get_next_sample\u001b[0;34m(self, sample, i, hist, signal_rates, noise_rates, times, p, corrector)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# for predictor, (ε_i, ε_i-1, ..., ε_i-p+1), shape : (p,),\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# for corrector, (ε_i+1, λ_i, ..., ε_i-p+1), shape : (p+1,)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m datas \u001b[38;5;241m=\u001b[39m hist[i\u001b[38;5;241m-\u001b[39mp\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:i\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m corrector \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 55\u001b[0m data_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([coeff \u001b[38;5;241m*\u001b[39m (signal_diff\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m noise_diff\u001b[38;5;241m*\u001b[39mdata[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m coeff, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(coeffs, datas)])\n\u001b[1;32m     56\u001b[0m next_sample \u001b[38;5;241m=\u001b[39m sample \u001b[38;5;241m+\u001b[39m data_sum\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_sample\n",
      "File \u001b[0;32m~/logpx_samplers_scpark/solvers/adams_dual_solver.py:55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# for predictor, (ε_i, ε_i-1, ..., ε_i-p+1), shape : (p,),\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# for corrector, (ε_i+1, λ_i, ..., ε_i-p+1), shape : (p+1,)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m datas \u001b[38;5;241m=\u001b[39m hist[i\u001b[38;5;241m-\u001b[39mp\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:i\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m corrector \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 55\u001b[0m data_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([coeff \u001b[38;5;241m*\u001b[39m (\u001b[43msignal_diff\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise_diff\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m coeff, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(coeffs, datas)])\n\u001b[1;32m     56\u001b[0m next_sample \u001b[38;5;241m=\u001b[39m sample \u001b[38;5;241m+\u001b[39m data_sum\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_sample\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (16) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from solvers.euler_solver import Euler_Solver\n",
    "from solvers.dpm_solver import DPM_Solver\n",
    "from solvers.adams_dual_solver import Adams_Dual_Solver\n",
    "\n",
    "pos_texts = [\"A serene twilight view of a traditional Korean hanok village nestled between misty mountain slopes: curved midnight-blue tiled eaves, softly glowing paper lanterns swaying in the breeze; ancient pine trees arching over stone pathways; intricate wooden lattice windows casting delicate shadows; a lone scholar in flowing hanbok practicing calligraphy beside a koi pond with lotus petals drifting on the water; cinematic 8K ultra-realism with dynamic volumetric moonlight filtering through morning mist; painterly strokes blending classical Joseon-era ink wash with modern hyperrealism; shot on RED Monstro 8K, 50 mm f/1.2 lens; subtle film grain; maximum fidelity; emotional atmosphere.\"]\n",
    "neg_texts = [\"lowres, bad anatomy, deformed, blurry, pixelated, oversaturated, underexposed, overexposed, artifact, jpeg artifacts, watermark, text, logo, extra limbs, mutated hands, unnatural colors, noisy background, out of focus, poor composition, cultural clichés, stereotype exaggeration, flat lighting, glitch\"]\n",
    "\n",
    "model_fn, noise_schedule, latents = model.get_model_fn(pos_conds=pos_texts, neg_conds=neg_texts, guidance_scale=4.5, seeds=[42])\n",
    "\n",
    "solver = Euler_Solver(model_fn, noise_schedule, algorithm_type='vector_prediction')\n",
    "latent_samples = solver.sample(latents, steps=100, skip_type='time_uniform_flow', flow_shift=3.0)\n",
    "pixel_samples = model.decode_vae(latent_samples)\n",
    "euler_sample = pixel_samples[0]\n",
    "\n",
    "solver = DPM_Solver(model_fn, noise_schedule, algorithm_type='data_prediction')\n",
    "latent_samples = solver.sample(latents, steps=20, order=2, skip_type=\"time_uniform_flow\", method=\"multistep\", flow_shift=3.0)\n",
    "pixel_samples = model.decode_vae(latent_samples)\n",
    "dpm_sample = pixel_samples[0]\n",
    "\n",
    "solver = Adams_Dual_Solver(model_fn, noise_schedule, algorithm_type='dual_prediction')\n",
    "latent_samples = solver.sample(latents, steps=20, order=2, skip_type=\"time_uniform_flow\", flow_shift=3.0)\n",
    "pixel_samples = model.decode_vae(latent_samples)\n",
    "adams1_sample = pixel_samples[0]\n",
    "\n",
    "show_compare([euler_sample, dpm_sample, adams1_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
