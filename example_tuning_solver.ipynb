{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter notebook auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbones.sana import SANA\n",
    "\n",
    "# 사용 예\n",
    "model = SANA()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_compare(euler_img, dpm_img):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "    axes[0].imshow(euler_img); axes[0].axis('off'); axes[0].set_title('Euler')\n",
    "    axes[1].imshow(dpm_img);  axes[1].axis('off'); axes[1].set_title('Diff-Solver')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/wl-zhao/DC-Solver/blob/f82d0601851b483d1dc06fc97e443588c6c9d9b0/stable-diffusion/scripts/sample_diffusion_dc_solver.py#L77\n",
    "# https://github.com/wl-zhao/DC-Solver/blob/f82d0601851b483d1dc06fc97e443588c6c9d9b0/stable-diffusion/ldm/models/diffusion/dc_solver/sampler.py#L86\n",
    "import os \n",
    "import torch\n",
    "import json\n",
    "from solvers.euler_solver import Euler_Solver\n",
    "\n",
    "B, C, H, W = model.get_model_fn(pos_text=\"\")[2].shape\n",
    "\n",
    "print(B, C, H, W)\n",
    "\n",
    "batch_size = 10 \n",
    "steps = 10 \n",
    "gt_steps = 200\n",
    "guidance_scale=4.5\n",
    "\n",
    "noise_path = f\"solvers/tuning_data/dc_solver/noise/default.pth\"\n",
    "caption_path = f\"solvers/tuning_data/dc_solver/caption/default.json\"\n",
    "ddim_gt_path = f\"solvers/tuning_data/dc_solver/ddim_gt/default.pth\"\n",
    "dc_ratios_path = f\"solvers/tuning_data/dc_solver/dc_ratios/default.json\"\n",
    "neg_text = \"lowres, bad anatomy, deformed, blurry, pixelated, oversaturated, underexposed, overexposed, artifact, jpeg artifacts, watermark, text, logo, extra limbs, mutated hands, unnatural colors, noisy background, out of focus, poor composition, cultural clichés, stereotype exaggeration, flat lighting, glitch\"\n",
    "\n",
    "os.makedirs(os.path.dirname(noise_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(caption_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(ddim_gt_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(dc_ratios_path), exist_ok=True)\n",
    "\n",
    "# 앗 Diffuser 로 해야하네 ??!?!?\n",
    "# https://github.com/wl-zhao/DC-Solver/blob/f82d0601851b483d1dc06fc97e443588c6c9d9b0/diffusers/scripts/sample_dc_solver.py#L85\n",
    "# https://github.com/wl-zhao/DC-Solver/blob/f82d0601851b483d1dc06fc97e443588c6c9d9b0/diffusers/src/diffusers/schedulers/scheduling_dcsolver_multistep.py#L873\n",
    "\n",
    "# 1. noise 파일 저장 \n",
    "if os.path.isfile(noise_path):\n",
    "    noise = torch.load(noise_path).to(model.device)\n",
    "else:\n",
    "    shape = (batch_size, C, H, W)\n",
    "    noise = torch.randn(shape, device=model.device, dtype=model.dtype)\n",
    "    torch.save(noise, noise_path)\n",
    "\n",
    "# 2. caption 파일 로드 \n",
    "with open(caption_path, \"r\") as f:\n",
    "    captions = json.load(f)\n",
    "prompts = [item['caption'] for item in captions]\n",
    "\n",
    "# 3. ddim_gt 파일 저장 \n",
    "if not os.path.isfile(ddim_gt_path):\n",
    "    print('ddim gt does not exist, generate for once')\n",
    "    # ddim_gt = generate_gt( noise, prompts)\n",
    "    def get_callback(t_list, latent_list):\n",
    "        def callback(t, latents):\n",
    "            t_list.append(t)\n",
    "            latent_list.append(latents)\n",
    "        return callback\n",
    "    \n",
    "    latent_list_batch_dim = []\n",
    "    \n",
    "    for i, prompt in enumerate(prompts):\n",
    "        t_list = []\n",
    "        latent_list_time_dim = []\n",
    "        callback = get_callback(t_list, latent_list_time_dim)\n",
    "        print(i, prompt)\n",
    "\n",
    "        single_noise = noise[i:i+1]\n",
    "        model_fn, noise_schedule, _ = model.get_model_fn(pos_text=prompt, neg_text=neg_text, guidance_scale=guidance_scale, num_steps=gt_steps, seed=42)\n",
    "\n",
    "\n",
    "        # 1. GT 생성을 위해서 get_model_fn 을 batch 형태로 처리할 수 있어야 함. \n",
    "        # 2. ***** tuning을 하기 위해서 model_fn을 batch 형태로 만들어야 함. *****\n",
    "\n",
    "\n",
    "        solver = Euler_Solver(model_fn, noise_schedule, callback_fn=callback)\n",
    "        _img = solver.sample(single_noise, steps=gt_steps, skip_type='time_uniform_flow', flow_shift=3.0)\n",
    "\n",
    "        latent_list_batch_dim.append(torch.stack(latent_list_time_dim, dim=1).squeeze(0)) # T, C, H, W\n",
    "\n",
    "    ddim_gt = {\n",
    "        'ts': torch.stack(t_list),\n",
    "        'intermediates': torch.stack(latent_list_batch_dim, dim=0),\n",
    "    }\n",
    "    torch.save(ddim_gt, ddim_gt_path)\n",
    "    \n",
    "else:\n",
    "    ddim_gt = torch.load(ddim_gt_path, map_location=model.device)\n",
    "    \n",
    "    if ddim_gt['intermediates'].shape[0] > batch_size:\n",
    "        ddim_gt['intermediates'] = ddim_gt['intermediates'][:batch_size]\n",
    "        prompts = prompts[:batch_size]\n",
    "\n",
    "# 4. sample --> Scheduler에 ddim_gt 넣으면 알아서 search mode로 동작하는 듯. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
